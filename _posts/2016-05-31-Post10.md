---
layout: post
title: Day 10-14 27/5/16-31/5/16
---
Studied Neural networks from Andrew Ng's Course (week 4 and 5). Studied the mathematics involved in backpropagation from a UC Berkley course notes (https://inst.eecs.berkeley.edu/~cs182/sp06/notes.php).
Studied MNIST Tutorial from tensorflow website and implemented it. Tried some variants and the results were as follows-
The default implementation without any hidden layer resulted in around 91-92% accoracy. On applying 1 hidden layer got around 92-93% accuacy. With 2 hidden layers, it touched 96.27% accuracy. With 3 hiddden layers, it touched 98.53% accuracy. With 4 hidden layers, it was somewhere around 98% only. In all these computations, the hyperparameters were optimized manually and weights and biases were initialized with random_normal distribution function and its stddev were also optimized.
Then studied about Convolutional Neural Networks from a Stanford course notes (http://cs231n.github.io/convolutional-networks/).
Lastly studied Deep MNIST tutorial from tensorflow website and implemented it.
