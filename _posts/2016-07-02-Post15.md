---
layout: post
title: Day 31-36 27/6/16-2/7/16
---
1.Last time around I was stuck with tensorflow's error:
"valueerror: graphdef cannot be larger than 2gb."
When i was varying various parameters, basically there were 3 for loops and within them, the graph and session was being started and closed each time..what one would expect is that when when the session closes, it should clear all the memory..that's what we mean by closing a session basically..but tensorflow doesn't clean the memory by default..so, for each iteration, it goes on allocating new space for storing values and hence the 2GB limit gets exceeded..I googled regarding it and tried some suggestions but haven't yet got through with it..
2. Aadil suggested that as the algorithm is ready, I also code for getting the visualisation of the dataflow graph. So, i started on it and added summaries to the code. After adding the summaries, the code had some bugs and it took a while to identify and debug them.
3. Then, on running the code and seeing the visualisation, I realised that initially we had made a numpy model and then integrated it into tensorflow. But, almost all of pre-processing was still coded in numpy. So, I can't add summaries for that and can't integrate the pre-processing in the dataflow graph. We can keep converting numpy arrays to tensors and the other way around but that will make the code much slower when it runs. So, then, I converted all of numpy implementation into tensorflow analogs. But, there were a lot of issues, as tensorflow is new now and still in it's early stages, most of tensorflow models are for ML related stuff and not for other miscellaneous tasks. It's horrible to the extent that it doesn't contain inbuilt function for sorting arrays along some dimension. This was one of the major issues where I had to code sorting in tensorflow and it didn't workout much in the end as tensorflow sucks even more when it comes to building loops. Then, on browsing for other options, I found a way out. For evaluating our computations, tensorflow has only 2 inbuilt functions and thankfully, one of them serves the exact task that I was looking for. Once that was done, in short time my code was up and running again. And, now I think it was worth converting everything to tensorflow based implementation. Previously I was able to achieve 99.8% accuracy..and now I am able to get 99.96% accuracy.
4. Aadil has now suggested to test the code on real user streams and Adarsh will provide access to that data. I am hopeful that, with such good accuracy on the existing dataset, it should not take long to tweak code and optimize for the new dataset.
